<!DOCTYPE html>
<html data-wf-domain="DisCo.github.io" data-wf-page="5e6fb768456f961381500a5f" data-wf-site="51e0d73d83d06baa7a00000f">
<head>
<meta charset = "UTF-8">
<title>DisCo</title>
<script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
<script type="text/javascript">WebFont.load({  google: {    families: ["Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic","Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic","Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic","Changa One:400,400italic","Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic","Varela Round:400","Bungee Shade:regular","Roboto:300,regular,500"]  }});</script>
<script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>
<link href="./style.css" rel="stylesheet" type="text/css"/>
<style>
.wf-loading * {
    opacity: 0;
}
</style>
</head>


<body bgcolor="black">
  <div class="section hero nerf-_v2">
    <div class="container-2 nerf_header_v2 w-container">
      <h1 class="nerf_title_v2">DisCo: Disentangled Implicit Content and Rhythm Learning for Diverse Co-Speech Gesture Synthesis</h1>
      <!-- <h1 class="nerf_subheader_v2">Haiyang Liu, Naoya Iwamoto, Zihao Zhu, Zhengqing Li, You Zhou, Elif Bozkurt, Bo Zheng</h1>
      <span class="nerf_subheader_v2">ACMMM 2022</span> -->
      <div class="link_column_nerf_v2 w-row">
        <div class="w-col w-col-6 w-col-small-4 w-col-tiny-4">
          <a href="https://DisCo.github.io/disco/" target="_blank" class="link-block w-inline-block">
            <img src="./paper.png" alt="paper" class="paper_img image-8 github_icon_nerf_v2"/></a>
      </div>
      <div class="w-col w-col-6 w-col-small-4 w-col-tiny-4">
        <a href="https://github.com/PantoMatrix/DisCo" target="_blank" class="link-block w-inline-block">
        <img src="./github.png" alt="paper" class="paper_img image-8 github_icon_nerf_v2"/></a>
      </div>
      </div>
      <div class="paper_code_nerf w-row">
        <div class="w-col w-col-6 w-col-small-4 w-col-tiny-4">
          <div class="text-block-2"><strong class="bold-text-nerf_v2">Paper</strong></div>
        </div>
        <div class="w-col w-col-6 w-col-small-4 w-col-tiny-4"><div class="text-block-2">
            <strong class="bold-text-nerf_v2">Code</strong></div>
        </div>
      </div>

      <div> 
          <span class="center"><img src="./teaser.png"></span>
      </div>
              
      <div class="nerf_slide_nav w-slider-nav w-slider-nav-invert w-round"></div></div></div>
                          
      <div data-anchor="slide1" class="section nerf_section">
          <div class="grey_container w-container">
            <h2 class="grey-heading_nerf">Abstract</h2>
            <p class="paragraph-3 nerf_text">Current co-speech gestures synthesis methods struggle with generating diverse motions and typically collapse to single or few frequent motion sequences, which are trained on original data distribution with customized models and strategies. We tackle this problem by temporally clustering motion sequences into content and rhythm segments and then training on content-balanced data distribution. In particular, by clustering motion sequences, we have observed for each rhythm pattern, some motions appear frequently, while others appear less. This imbalance results in the difficulty of generating low frequent occurrence motions and it cannot be easily solved by resampling, due to the inherent many-to-many mapping between content and rhythm. Therefore, we present DisCo, which disentangles motion into implicit content and rhythm features by contrastive loss for adopting different data balance strategies. Besides, to model the inherent mapping between content and rhythm features, we design a diversity-and-inclusion network (DIN), which firstly generates content features candidates and then selects one candidate by learned voting. Experiments on two public datasets, Trinity and S2G-Ellen, justify that DisCo generates more realistic and diverse motions than state-of-the-art methods.</p>

      </div></div>

      <div data-anchor="slide1" class="section nerf_section">
        <div class="w-container"><h2 class="grey-heading_nerf">Body Results</h2>
          <div style="padding-top:56.17021276595745%" id="w-node-e5e45b1d55ac-81500a5f" class="w-embed-youtubevideo stega_movie youtube">
            <iframe src="https://www.youtube.com/embed/IqtvTkbm4QY?rel=1&amp;controls=1&amp;autoplay=0&amp;mute=0&amp;start=0" frameBorder="0" style="position:absolute;left:0;top:0;width:100%;height:100%;pointer-events:auto" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>
          </div>
        </div>

      <div data-anchor="slide1" class="section nerf_section">
        <div class="w-container"><h2 class="grey-heading_nerf">Body + Hands Results</h2>
          <div style="padding-top:56.17021276595745%" id="w-node-e5e45b1d55ac-81500a5f" class="w-embed-youtubevideo stega_movie youtube">
            <iframe src="https://www.youtube.com/embed/5Ywqizs3g3A?rel=1&amp;controls=1&amp;autoplay=0&amp;mute=0&amp;start=0" frameBorder="0" style="position:absolute;left:0;top:0;width:100%;height:100%;pointer-events:auto" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>
          </div>
        </div>
        </div>
      
      <div data-anchor="slide1" class="section nerf_section">
        <div class="w-container"><h2 class="grey-heading_nerf">Supplementary Video</h2>
          <div style="padding-top:56.17021276595745%" id="w-node-e5e45b1d55ac-81500a5f" class="w-embed-youtubevideo stega_movie youtube">
            <iframe src="https://www.youtube.com/embed/FIrpBNywzqQ?rel=1&amp;controls=1&amp;autoplay=0&amp;mute=0&amp;start=0" frameBorder="0" style="position:absolute;left:0;top:0;width:100%;height:100%;pointer-events:auto" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>
          </div>
        </div>
        </div>
      
      <div data-anchor="slide1" class="section nerf_section">
          <div class="grey_container w-container">
            <h2 class="grey-heading_nerf">Reference</h2>
            <p class="paragraph-3 nerf_text">Current co-speech gestures synthesis methods struggle with generating diverse motions and typically collapse to single or few frequent motion sequences, which are trained on original data distribution with customized models and strategies. We tackle this problem by temporally clustering motion sequences into content and rhythm segments and then training on content-balanced data distribution. In particular, by clustering motion sequences, we have observed for each rhythm pattern, some motions appear frequently, while others appear less. This imbalance results in the difficulty of generating low frequent occurrence motions and it cannot be easily solved by resampling, due to the inherent many-to-many mapping between content and rhythm. Therefore, we present DisCo, which disentangles motion into implicit content and rhythm features by contrastive loss for adopting different data balance strategies. Besides, to model the inherent mapping between content and rhythm features, we design a diversity-and-inclusion network (DIN), which firstly generates content features candidates and then selects one candidate by learned voting. Experiments on two public datasets, Trinity and S2G-Ellen, justify that DisCo generates more realistic and diverse motions than state-of-the-art methods.</p>

      </div></div>
	                        

<div class="white_section_nerf">
	<div class="w-container">	
</div></div>

<script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.4.1.min.220afd743d.js?site=51e0d73d83d06baa7a00000f" type="text/javascript" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.3057c11af.js" type="text/javascript"></script><!--[if lte IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif]-->

</body>
</html>
